{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1_HS8yMMR0ZrcmdOO7d_JB9jPqNvkBhBr",
      "authorship_tag": "ABX9TyO3FyaQ8UqXEmIf1djZ0Dcp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SVz54/Data-Exfiltration-Prevention/blob/main/9517.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Kaggle download (same as before) ---\n",
        "import os, json, shutil, zipfile, glob, pathlib\n",
        "\n",
        "os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "if not os.path.exists('/root/.kaggle/kaggle.json') and os.path.exists('/content/kaggle.json'):\n",
        "    shutil.move('/content/kaggle.json', '/root/.kaggle/kaggle.json')\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "!pip -q install kaggle\n",
        "DATA_DIR = \"/content/AgroPest12\"\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "!kaggle datasets download -d rupankarmajumdar/crop-pests-dataset -p $DATA_DIR -q\n",
        "\n",
        "# Unzip (overwrite if re-running)\n",
        "zip_files = glob.glob(f\"{DATA_DIR}/*.zip\")\n",
        "assert zip_files, \"Zip not found â€“ did the Kaggle download succeed?\"\n",
        "zip_path = zip_files[0]\n",
        "!unzip -q -o \"$zip_path\" -d \"$DATA_DIR\"\n",
        "\n",
        "# --- Auto-detect BASE: the folder that contains train/valid/test with images+labels ---\n",
        "def find_yolo_base(root):\n",
        "    for p, d, f in os.walk(root):\n",
        "        if (os.path.isdir(os.path.join(p, \"train\", \"images\")) and\n",
        "            os.path.isdir(os.path.join(p, \"train\", \"labels\")) and\n",
        "            os.path.isdir(os.path.join(p, \"valid\", \"images\")) and\n",
        "            os.path.isdir(os.path.join(p, \"valid\", \"labels\"))):\n",
        "            return p\n",
        "    return None\n",
        "\n",
        "BASE = find_yolo_base(DATA_DIR)\n",
        "assert BASE is not None, f\"Could not find YOLO folders under {DATA_DIR}. Found: {os.listdir(DATA_DIR)}\"\n",
        "print(\"BASE:\", BASE)\n",
        "print(\"train samples:\", len(glob.glob(os.path.join(BASE, \"train/images/*.jpg\"))))\n",
        "print(\"val samples:\", len(glob.glob(os.path.join(BASE, \"valid/images/*.jpg\"))))\n",
        "print(\"test samples:\", len(glob.glob(os.path.join(BASE, \"test/images/*.jpg\"))))\n",
        "BASE = pathlib.Path(BASE)  # keep as Path for later cells\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OobgjuldDYN6",
        "outputId": "f4a8cb5f-f8fa-4f43-b1d1-fd0108a418e4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/rupankarmajumdar/crop-pests-dataset\n",
            "License(s): MIT\n",
            "BASE: /content/AgroPest12\n",
            "train samples: 11502\n",
            "val samples: 1095\n",
            "test samples: 546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "yaml_path = BASE / \"data.yaml\"\n",
        "txt = f\"\"\"# AgroPest-12\n",
        "path: {BASE.as_posix()}\n",
        "train: train/images\n",
        "val: valid/images\n",
        "test: test/images\n",
        "names:\n",
        "  0: aphid\n",
        "  1: armyworm\n",
        "  2: beetle\n",
        "  3: bollworm\n",
        "  4: grasshopper\n",
        "  5: leafhopper\n",
        "  6: locust\n",
        "  7: mealybug\n",
        "  8: mosquito\n",
        "  9: moth\n",
        "  10: sawfly\n",
        "  11: weevil\n",
        "\"\"\"\n",
        "yaml_path.write_text(txt)\n",
        "print(\"Wrote:\", yaml_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xS-cqI_WEFNq",
        "outputId": "a872cc0e-b2b6-414b-ba01-5443751f530d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote: /content/AgroPest12/data.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import os, glob\n",
        "\n",
        "model = YOLO('yolov8n.pt')   # tiny + fast; swap to yolov8s.pt later if you want\n",
        "\n",
        "# use a handful of val images for a demo run\n",
        "val_imgs = sorted(glob.glob(str(BASE / 'valid/images/*.jpg')))[:12]\n",
        "print(\"Demo images:\", len(val_imgs))\n",
        "\n",
        "pred_root = \"/content/preds\"\n",
        "res = model.predict(val_imgs, conf=0.25, save=True, project=pred_root, name=\"yolo_preds\", exist_ok=True, imgsz=640)\n",
        "print(\"Saved predicted images to:\", pred_root + \"/yolo_preds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJTHuwsgEcql",
        "outputId": "41d4259b-5cf3-4472-9ae4-c5111dd1e8bd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Demo images: 12\n",
            "\n",
            "0: 640x640 (no detections), 339.1ms\n",
            "1: 640x640 (no detections), 339.1ms\n",
            "2: 640x640 1 bear, 339.1ms\n",
            "3: 640x640 (no detections), 339.1ms\n",
            "4: 640x640 1 cat, 339.1ms\n",
            "5: 640x640 1 horse, 339.1ms\n",
            "6: 640x640 (no detections), 339.1ms\n",
            "7: 640x640 1 person, 339.1ms\n",
            "8: 640x640 1 bird, 1 horse, 339.1ms\n",
            "9: 640x640 1 teddy bear, 339.1ms\n",
            "10: 640x640 1 bird, 339.1ms\n",
            "11: 640x640 (no detections), 339.1ms\n",
            "Speed: 12.0ms preprocess, 339.1ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m/content/preds/yolo_preds\u001b[0m\n",
            "Saved predicted images to: /content/preds/yolo_preds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q uninstall -y pytorch-grad-cam grad-cam || true\n",
        "!pip -q install --no-cache-dir \"git+https://github.com/jacobgil/pytorch-grad-cam.git\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogXJTGihElT8",
        "outputId": "0f13c098-0a07-4756-f64f-8aeb2d17b85a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping pytorch-grad-cam as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for grad-cam (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_grad_cam, inspect\n",
        "from pytorch_grad_cam.utils import model_targets\n",
        "print(\"grad-cam version:\", getattr(pytorch_grad_cam, \"__version__\", \"git\"))\n",
        "print(\"Has YOLOv8Target:\", hasattr(model_targets, \"YOLOv8Target\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QZUH7arIYCn",
        "outputId": "1d918da7-698b-4914-aa04-f5fce56fa39c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grad-cam version: git\n",
            "Has YOLOv8Target: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Single-image, low-memory, true Grad-CAM on YOLOv8 (crop-only) ---\n",
        "import os, gc, cv2, torch, numpy as np, torch.nn as nn\n",
        "from ultralytics import YOLO\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "\n",
        "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
        "\n",
        "# 1) detection model (reuse your existing one)\n",
        "model_det = YOLO('yolov8n.pt')    # or reuse 'model' if it's already loaded\n",
        "\n",
        "# 2) clean model for CAM (never use .predict() on this)\n",
        "model_cam = YOLO('yolov8n.pt')\n",
        "device = \"cpu\"                     # keep CPU for stability\n",
        "model_cam.model.to(device).eval()\n",
        "\n",
        "def last_conv2d(ultra_model):\n",
        "    last = None\n",
        "    for _, m in ultra_model.model.named_modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            last = m\n",
        "    return last\n",
        "\n",
        "target_layer = last_conv2d(model_cam)\n",
        "assert target_layer is not None\n",
        "\n",
        "def load_rgb_float(path):\n",
        "    bgr = cv2.imread(path)\n",
        "    rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
        "    return rgb, (rgb.astype(np.float32)/255.0)\n",
        "\n",
        "def clamp_int(v, lo, hi):\n",
        "    return max(lo, min(int(v), hi))\n",
        "\n",
        "# Pick the FIRST val image that yields any detection with the COCO model\n",
        "chosen = None\n",
        "chosen_det = None\n",
        "for ip in sorted((BASE/'valid/images').glob('*.jpg'))[:50]:  # look at at most 50\n",
        "    r = model_det(str(ip), conf=0.35, imgsz=320)[0]\n",
        "    if r.boxes is not None and len(r.boxes) > 0:\n",
        "        chosen = str(ip)\n",
        "        chosen_det = r\n",
        "        break\n",
        "\n",
        "if chosen is None:\n",
        "    raise RuntimeError(\"No detections found on first 50 val images with COCO weights; try lowering conf or pick another image.\")\n",
        "\n",
        "print(\"Using image:\", chosen)\n",
        "rgb, rgbf = load_rgb_float(chosen)\n",
        "h, w = rgb.shape[:2]\n",
        "\n",
        "# Take top-confidence detection and crop around it (shrinks tensor size a lot)\n",
        "k = int(torch.argmax(chosen_det.boxes.conf).item())\n",
        "x1,y1,x2,y2 = chosen_det.boxes.xyxy[k].tolist()\n",
        "pad = 0.15\n",
        "xa = clamp_int(x1 - (x2-x1)*pad, 0, w-1)\n",
        "ya = clamp_int(y1 - (y2-y1)*pad, 0, h-1)\n",
        "xb = clamp_int(x2 + (x2-x1)*pad, 0, w-1)\n",
        "yb = clamp_int(y2 + (y2-y1)*pad, 0, h-1)\n",
        "\n",
        "crop = rgb[ya:yb, xa:xb]\n",
        "cropf = crop.astype(np.float32)/255.0\n",
        "inp = torch.from_numpy(cropf.transpose(2,0,1)).unsqueeze(0).to(device).float()\n",
        "inp.requires_grad_(True)\n",
        "\n",
        "# Rerun detection on the CROP to get a matching class index in the crop frame\n",
        "r_crop = model_det(crop[..., ::-1], conf=0.25, imgsz=320)[0]  # BGR expected; we pass RGB->BGR by reversing channels\n",
        "if r_crop.boxes is None or len(r_crop.boxes)==0:\n",
        "    raise RuntimeError(\"No detection in crop; try a different image or lower conf.\")\n",
        "\n",
        "top_cls = int(r_crop.boxes.cls[torch.argmax(r_crop.boxes.conf)].item())\n",
        "\n",
        "# Custom class-specific target: pick the strongest prediction row for 'top_cls'\n",
        "class YoloRowTarget:\n",
        "    def __init__(self, cls_idx, model_ref):\n",
        "        self.cls_idx = int(cls_idx)\n",
        "        self.nc = model_ref.model.model[-1].nc\n",
        "    def __call__(self, outputs):\n",
        "        pred = outputs[0]  # (N, 4+nc[+obj])\n",
        "        if pred.size(1) > 4 + self.nc:\n",
        "            obj = pred[:,4].sigmoid()\n",
        "            cls = pred[:,5 + self.cls_idx].sigmoid()\n",
        "            score = (obj*cls).max()\n",
        "        else:\n",
        "            cls = pred[:,4 + self.cls_idx].sigmoid()\n",
        "            score = cls.max()\n",
        "        return score\n",
        "\n",
        "target = YoloRowTarget(top_cls, model_cam)\n",
        "\n",
        "cam = GradCAM(model=model_cam.model, target_layers=[target_layer])\n",
        "cam_map = cam(input_tensor=inp, targets=[target], eigen_smooth=False)[0]  # no smoothing to save RAM\n",
        "\n",
        "# Overlay and save\n",
        "vis = show_cam_on_image(cropf, cam_map, use_rgb=True)\n",
        "out_dir = \"/content/gradcam\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "out = os.path.join(out_dir, os.path.basename(chosen).replace(\".jpg\",\"_CROP_gradcam.jpg\"))\n",
        "cv2.imwrite(out, cv2.cvtColor(vis, cv2.COLOR_RGB2BGR))\n",
        "print(\"Saved:\", out)\n",
        "\n",
        "# cleanup\n",
        "del inp, cam_map, crop, cropf, r_crop, chosen_det\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fI2kHxtJKk6B",
        "outputId": "e0888784-ae76-4c71-c5d3-8cf47debadf8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/AgroPest12/valid/images/Weevil-101-_jpg.rf.7b2714887709397bf4467aee16ea2e79.jpg: 320x320 1 bird, 109.7ms\n",
            "Speed: 8.8ms preprocess, 109.7ms inference, 1.2ms postprocess per image at shape (1, 3, 320, 320)\n",
            "Using image: /content/AgroPest12/valid/images/Weevil-101-_jpg.rf.7b2714887709397bf4467aee16ea2e79.jpg\n",
            "\n",
            "0: 320x320 1 bird, 99.1ms\n",
            "Speed: 6.9ms preprocess, 99.1ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 320)\n",
            "Saved: /content/gradcam/Weevil-101-_jpg.rf.7b2714887709397bf4467aee16ea2e79_CROP_gradcam.jpg\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}